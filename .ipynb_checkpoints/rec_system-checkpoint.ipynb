{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.sparse as sp\n",
    "\n",
    "data_100k = 'ml-100k/u.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosSimilarity(matrix):\n",
    "    similarity_matrix = cosine_similarity(matrix)\n",
    "    print(\"Cosine Similarity Matrix Sample:\")\n",
    "    print(similarity_matrix[:5, :5])\n",
    "    print(\"=\" * 120)\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a distance-based similarity score for person1 and person2\n",
    "def sim_distance(prefs,person1,person2):\n",
    "    # Get the list of shared_items\n",
    "    si={}\n",
    "    for item in prefs[person1]: \n",
    "        if item in prefs[person2]: si[item]=1\n",
    "\n",
    "    # if they have no ratings in common, return 0\n",
    "    if len(si)==0: return 0\n",
    "\n",
    "    # Add up the squares of all the differences\n",
    "    sum_of_squares=sum([pow(prefs[person1][item]-prefs[person2][item],2) \n",
    "                        for item in prefs[person1] if item in prefs[person2]])\n",
    "\n",
    "    return 1/(1+sum_of_squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the Pearson correlation coefficient for p1 and p2\n",
    "def sim_pearson(prefs,p1,p2):\n",
    "    # Get the list of mutually rated items\n",
    "    si={}\n",
    "    for item in prefs[p1]: \n",
    "        if item in prefs[p2]: si[item]=1\n",
    "\n",
    "    # if they are no ratings in common, return 0\n",
    "    if len(si)==0: return 0\n",
    "\n",
    "    # Sum calculations\n",
    "    n=len(si)\n",
    "    \n",
    "    # Sums of all the preferences\n",
    "    sum1=sum([prefs[p1][it] for it in si])\n",
    "    sum2=sum([prefs[p2][it] for it in si])\n",
    "    \n",
    "    # Sums of the squares\n",
    "    sum1Sq=sum([pow(prefs[p1][it],2) for it in si])\n",
    "    sum2Sq=sum([pow(prefs[p2][it],2) for it in si]) \n",
    "    \n",
    "    # Sum of the products\n",
    "    pSum=sum([prefs[p1][it]*prefs[p2][it] for it in si])\n",
    "    \n",
    "    # Calculate r (Pearson score)\n",
    "    num=pSum-(sum1*sum2/n)\n",
    "    den=sqrt((sum1Sq-pow(sum1,2)/n)*(sum2Sq-pow(sum2,2)/n))\n",
    "    if den==0: return 0\n",
    "\n",
    "    r=num/den\n",
    "\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(test_size=0.2, datafile='ml-100k/u.data', header=['uid','iid','ratings','timestamp'], sep='\\t', seed=0):\n",
    "    # Read CSV File into A Pandas DataFrame\n",
    "    df = pd.read_csv(datafile, header=None, names=header, sep=sep, engine='python')\n",
    "    df.drop(columns='timestamp')\n",
    "    print(df.head())\n",
    "    # The Number of User and Items\n",
    "    num_users, num_items = df[header[0]].unique().shape[0], df[header[1]].unique().shape[0]\n",
    "    # The minimum id of user and item (because in Python array index is from 0)\n",
    "    uid_min, iid_min = df['uid'].min(), df['iid'].min()\n",
    "\n",
    "    # Train and Test Dataset Splitting\n",
    "    train_df, test_df = train_test_split(np.asarray(df), test_size=test_size, random_state=seed)\n",
    "\n",
    "    # Change the data structure into sparse matrix\n",
    "    train = sp.csr_matrix((train_df[:, 2], (train_df[:, 0]-uid_min, train_df[:, 1]-iid_min)), shape=(num_users, num_items))\n",
    "    test = sp.csr_matrix((test_df[:, 2], (test_df[:, 0]-uid_min, test_df[:, 1]-iid_min)), shape=(num_users, num_items))\n",
    "\n",
    "    print(\"Number of Users: \" + str(num_users))\n",
    "    print(\"Number of Items: \" + str(num_items))\n",
    "    print(\"=\" * 120)\n",
    "\n",
    "    print(\"Sample Data: \" + str(train.getrow(0).toarray()))\n",
    "    print(\"=\" * 120)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "# def loadData(test_size=0.2, datafile='ml-100k/u.data', header=['uid','iid','ratings','timestamp'], sep='\\t', seed=0):\n",
    "#     # Read CSV File into A Pandas DataFrame\n",
    "#     df = pd.read_csv(datafile, header=None, names=header, sep=sep, engine='python')\n",
    "#     df = df.drop(columns='timestamp')\n",
    "#     print(df.head())\n",
    "#     # The Number of User and Items\n",
    "#     num_users, num_items = df[header[0]].unique().shape[0], df[header[1]].unique().shape[0]\n",
    "#     # The minimum id of user and item (because in Python array index is from 0)\n",
    "#     uid_min, iid_min = df['uid'].min(), df['iid'].min()\n",
    "#     uid_max, iid_max = df['uid'].max(), df['iid'].max()\n",
    "# #     print(uid_max,iid_max)\n",
    "# #     print(num_users)\n",
    "#     result = np.zeros((num_users, num_items))\n",
    "#     for index, row in df.iterrows():\n",
    "#         result[int(row['uid'])-1,int(row['iid'])-1] = int(row['ratings'])\n",
    "#     train, test = train_test_split(result, test_size=test_size, random_state = seed)\n",
    "#     return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Precision_and_Recall(pred_item_list, test_item_list):\n",
    "    # Calculate the Number of Occurrences of Testing Item IDs in the Prediction Item ID List\n",
    "    sum_relevant_item = 0\n",
    "    for item in test_item_list:\n",
    "        if item in pred_item_list:\n",
    "            sum_relevant_item += 1\n",
    "\n",
    "    # Calculate the Precision and Recall Value\n",
    "    precision = sum_relevant_item / len(pred_item_list)\n",
    "    recall = sum_relevant_item / len(test_item_list)\n",
    "\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   uid  iid  ratings  timestamp\n",
      "0  196  242        3  881250949\n",
      "1  186  302        3  891717742\n",
      "2   22  377        1  878887116\n",
      "3  244   51        2  880606923\n",
      "4  166  346        1  886397596\n",
      "Number of Users: 943\n",
      "Number of Items: 1682\n",
      "========================================================================================================================\n",
      "Sample Data: [[5 3 4 ... 0 0 0]]\n",
      "========================================================================================================================\n",
      "<class 'numpy.ndarray'>\n",
      "(943, 1682)\n",
      "(943, 1682)\n"
     ]
    }
   ],
   "source": [
    "train, test = loadData()\n",
    "train = train.toarray()\n",
    "test = test.toarray()\n",
    "print(type(train))\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVD:\n",
    "    def __init__(self,mat,K=20):\n",
    "        self.mat=mat\n",
    "        self.K=K\n",
    "        self.bi={}\n",
    "        self.bu={}\n",
    "        self.qi={}\n",
    "        self.pu={}\n",
    "        self.avg=np.mean(self.mat[:,2])\n",
    "        for i in range(self.mat.shape[0]):\n",
    "            uid=self.mat[i,0]\n",
    "            iid=self.mat[i,1]\n",
    "            self.bi.setdefault(iid,0)\n",
    "            self.bu.setdefault(uid,0)\n",
    "            self.qi.setdefault(iid,np.random.random((self.K,1))/10*np.sqrt(self.K))\n",
    "            self.pu.setdefault(uid,np.random.random((self.K,1))/10*np.sqrt(self.K))\n",
    "    def predict(self,uid,iid):  #预测评分的函数\n",
    "        #setdefault的作用是当该用户或者物品未出现过时，新建它的bi,bu,qi,pu，并设置初始值为0\n",
    "        self.bi.setdefault(iid,0)\n",
    "        self.bu.setdefault(uid,0)\n",
    "        self.qi.setdefault(iid,np.zeros((self.K,1)))\n",
    "        self.pu.setdefault(uid,np.zeros((self.K,1)))\n",
    "        rating=self.avg+self.bi[iid]+self.bu[uid]+np.sum(self.qi[iid]*self.pu[uid]) #预测评分公式\n",
    "        #由于评分范围在1到5，所以当分数大于5或小于1时，返回5,1.\n",
    "        if rating>5:\n",
    "            rating=5\n",
    "        if rating<1:\n",
    "            rating=1\n",
    "        return rating\n",
    "    def train(self,steps=30,gamma=0.04,Lambda=0.15):    #训练函数，step为迭代次数\n",
    "        print('train data size',self.mat.shape)\n",
    "        for step in range(steps):\n",
    "            print('step',step+1,'is running')\n",
    "            KK=np.random.permutation(self.mat.shape[0]) #随机梯度下降算法，kk为对矩阵进行随机洗牌\n",
    "            rmse=0.0\n",
    "            for i in range(self.mat.shape[0]):\n",
    "                j=KK[i]\n",
    "                uid=self.mat[j,0]\n",
    "                iid=self.mat[j,1]\n",
    "                rating=self.mat[j,2]\n",
    "                eui=rating-self.predict(uid, iid)\n",
    "                rmse+=eui**2\n",
    "                self.bu[uid]+=gamma*(eui-Lambda*self.bu[uid])  \n",
    "                self.bi[iid]+=gamma*(eui-Lambda*self.bi[iid])\n",
    "                tmp=self.qi[iid]\n",
    "                self.qi[iid]+=gamma*(eui*self.pu[uid]-Lambda*self.qi[iid])\n",
    "                self.pu[uid]+=gamma*(eui*tmp-Lambda*self.pu[uid])\n",
    "            gamma=0.93*gamma\n",
    "            print('rmse is',np.sqrt(rmse/self.mat.shape[0]))\n",
    "    def test(self,test_data):  #gamma以0.93的学习率递减\n",
    "        test_data=test_data\n",
    "        print('test data size',test_data.shape)\n",
    "        rmse=0.0\n",
    "        for i in range(test_data.shape[0]):\n",
    "            uid=test_data[i,0]\n",
    "            iid=test_data[i,1]\n",
    "            rating=test_data[i,2]\n",
    "            eui=rating-self.predict(uid, iid)\n",
    "            rmse+=eui**2\n",
    "        print('rmse of test data is',np.sqrt(rmse/test_data.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import *\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "class MF(object):\n",
    "    def __init__(self,train_matrix,test_matrix):\n",
    "        self.num_factors = 600 # Dimension of the Latent Factor\n",
    "        self.regs = 1e-3 # Regularizer Coefficient\n",
    "        self.lr = 0.01 # Learning Rate\n",
    "        self.epochs = 50 # How many number of Training Loops\n",
    "        self.batch_size = 128 # How many data is fed into the training algorithm in each epoch\n",
    "        # Initialize Parameters\n",
    "        self.num_factors = num_factors \n",
    "        self.regs = regularizer \n",
    "\n",
    "        self.lr = learning_rate \n",
    "        self.epochs = epochs \n",
    "        self.batch_size = batch_size \n",
    "\n",
    "        self.num_user, self.num_item = train_matrix.shape[0], train_matrix.shape[1]\n",
    "        # Store the user IDs in a list, the item IDs in a list and the ratings in a list\n",
    "        train_matrix, test_matrix = train_matrix.tocoo(), test_matrix.tocoo()\n",
    "        self.train_uid, self.train_iid, self.train_ratings = list(train_matrix.row),list(train_matrix.col),list(train_matrix.data)\n",
    "        self.test_uid, self.test_iid, self.test_ratings = list(test_matrix.row),list(test_matrix.col),list(test_matrix.data)\n",
    "\n",
    "        # Calculate the average of all ratings (the mu value in the equation)\n",
    "        self.mu = np.mean(self.train_ratings)\n",
    "\n",
    "        # Total number of training data instances\n",
    "        self.num_training = len(self.train_ratings)\n",
    "\n",
    "        # Number of batches\n",
    "        self.num_batch = int(self.num_training / self.batch_size)\n",
    "        print(\"Data Preparation Completed.\")\n",
    "\n",
    "    # Build the model for customized SGD algorithm\n",
    "        # Initialize all the parameters (Use Normal Distribution)\n",
    "        # bu and bi are vectors (Note the dimension)\n",
    "        self.bu = np.random.normal(scale = 1. / self.num_factors, size=[self.num_user])\n",
    "        self.bi = np.random.normal(scale = 1. / self.num_factors, size=[self.num_item])\n",
    "\n",
    "        # P and Q are matrices (Note the dimension)\n",
    "        self.P = np.random.normal(scale=1. / self.num_factors, size=[self.num_user, self.num_factors])\n",
    "        self.Q = np.random.normal(scale=1. / self.num_factors, size=[self.num_factors, self.num_item])\n",
    "        print(\"Parameter Initialization Completed.\")\n",
    "\n",
    "    # Training using SGD algorithm\n",
    "    def train_and_evaluate(self):\n",
    "        for epoch in range(self.epochs):\n",
    "            for uid, iid, ratings in list(zip(self.train_uid, self.train_iid, self.train_ratings)):\n",
    "                # The estimated rating\n",
    "                pred_r = self.mu + self.bu[uid] + self.bi[iid] + np.dot(self.Q[:, iid], self.P[uid, :])\n",
    "\n",
    "                # Calculate the loss of this specific user-item pair\n",
    "                error = ratings - pred_r\n",
    "\n",
    "                # Update the parameters\n",
    "                self.bu[uid] = self.bu[uid] + self.lr * (error - self.regs * self.bu[uid])\n",
    "                self.bi[iid] = self.bi[iid] + self.lr * (error - self.regs * self.bi[iid])\n",
    "                self.P[uid, :] = self.P[uid, :] + self.lr * (error * self.Q[:, iid] - self.regs * self.P[uid, :])\n",
    "                self.Q[:, iid] = self.Q[:, iid] + self.lr * (error * self.P[uid, :] - self.regs * self.Q[:, iid])\n",
    "            rms_test_list, rms_train_list = [], []\n",
    "\n",
    "            for uid, iid, ratings in list(zip(self.test_uid, self.test_iid, self.test_ratings)):\n",
    "                rms_test_list.append(\n",
    "                    (self.mu + self.bu[uid] + self.bi[iid] + np.dot(self.Q[:, iid], self.P[uid, :]) - ratings) ** 2)\n",
    "\n",
    "            for uid, iid, ratings in list(zip(self.train_uid, self.train_iid, self.train_ratings)):\n",
    "                rms_train_list.append(\n",
    "                    (self.mu + self.bu[uid] + self.bi[iid] + np.dot(self.Q[:, iid], self.P[uid, :]) - ratings) ** 2)\n",
    "\n",
    "            rms_test = np.sqrt(np.mean(rms_test_list))\n",
    "            rms_train = np.sqrt(np.mean(rms_train_list))\n",
    "            print(\"Epoch {0} Training: [RMS] {1} and Testing: [RMS] {2}\".format(epoch, rms_train, rms_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   uid  iid  ratings  timestamp\n",
      "0  196  242        3  881250949\n",
      "1  186  302        3  891717742\n",
      "2   22  377        1  878887116\n",
      "3  244   51        2  880606923\n",
      "4  166  346        1  886397596\n",
      "Number of Users: 943\n",
      "Number of Items: 1682\n",
      "========================================================================================================================\n",
      "Sample Data: [[5 3 4 ... 0 0 0]]\n",
      "========================================================================================================================\n",
      "Data Preparation Completed.\n",
      "Parameter Initialization Completed.\n",
      "Epoch 0 Training: [RMS] 0.9709943991077488 and Testing: [RMS] 0.9847204477041067\n",
      "Epoch 1 Training: [RMS] 0.947017208004226 and Testing: [RMS] 0.9648437886547285\n",
      "Epoch 2 Training: [RMS] 0.9362230037195872 and Testing: [RMS] 0.9564791473300163\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-69bd87ae4cff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloadData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_matrix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_and_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-ff86d28c3ef1>\u001b[0m in \u001b[0;36mtrain_and_evaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0;31m# Calculate the loss of this specific user-item pair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m                 \u001b[0merror\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mratings\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mpred_r\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0;31m# Update the parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_matrix, test_matrix = loadData()\n",
    "    model = MF(train_matrix, test_matrix)\n",
    "    model.train_and_evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd(mat, feature, steps=50, gama=0.02, lamda=0.3):\n",
    "    slowRate = 0.99\n",
    "    preRmse = 1000000000.0\n",
    "    nowRmse = 0.0\n",
    " \n",
    "    user_feature = np.matrix(np.random.rand(mat.shape[0], feature))\n",
    "    item_feature = np.matrix(np.random.rand(mat.shape[1], feature))\n",
    " \n",
    "    for step in range(steps):\n",
    "        rmse = 0.0  \n",
    "        n = 0  \n",
    "        for u in range(mat.shape[0]):\n",
    "            for i in range(mat.shape[1]):\n",
    "                if not np.isnan(mat[u,i]):\n",
    "                    pui = float(np.dot(user_feature[u,:], item_feature[i,:].T))\n",
    "                    eui = mat[u,i] - pui\n",
    "                    rmse += pow(eui, 2)\n",
    "                    n += 1 \n",
    "                    for k in range(feature):\n",
    "                        user_feature[u,k] += gama*(eui*item_feature[i,k] - lamda*user_feature[u,k])\n",
    "                        item_feature[i,k] += gama*(eui*user_feature[u,k] - lamda*item_feature[i,k]) # 原blog这里有错误 \n",
    " \n",
    "        nowRmse = np.sqrt(rmse * 1.0 / n)\n",
    "        print('step: %d      Rmse: %s' % ((step+1), nowRmse))\n",
    "        if (nowRmse < preRmse):  \n",
    "            preRmse = nowRmse\n",
    "        else:\n",
    "            break # 这个退出条件其实还有点问题\n",
    "        gama *= slowRate\n",
    "        step += 1\n",
    " \n",
    "    return user_feature, item_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1      Rmse: 0.7525733265976747\n",
      "step: 2      Rmse: 0.7644989532969478\n"
     ]
    }
   ],
   "source": [
    "user_feature, item_feature = svd(train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[2.94060540e-05, 5.84556900e-05, 2.89827418e-05, 4.91040562e-05,\n",
       "         3.49958660e-05],\n",
       "        [4.23850628e-05, 2.96976943e-05, 6.28733378e-05, 3.68993543e-05,\n",
       "         4.24204682e-05],\n",
       "        [3.55896979e-05, 2.68984183e-05, 5.31611075e-05, 2.70131844e-05,\n",
       "         3.37341240e-05],\n",
       "        ...,\n",
       "        [1.89295819e-04, 2.08726432e-04, 1.78494852e-04, 2.08848853e-04,\n",
       "         1.83884924e-04],\n",
       "        [7.73505190e-04, 8.63899001e-04, 7.27288939e-04, 8.62449982e-04,\n",
       "         7.53749646e-04],\n",
       "        [9.53059890e-04, 1.06275134e-03, 8.95077651e-04, 1.06019908e-03,\n",
       "         9.26962730e-04]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

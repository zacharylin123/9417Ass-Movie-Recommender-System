{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.sparse as sp\n",
    "\n",
    "data_100k = 'ml-100k/u.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosSimilarity(matrix):\n",
    "    similarity_matrix = cosine_similarity(matrix)\n",
    "    print(\"Cosine Similarity Matrix Sample:\")\n",
    "    print(similarity_matrix[:5, :5])\n",
    "    print(\"=\" * 120)\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a distance-based similarity score for person1 and person2\n",
    "def sim_distance(prefs,person1,person2):\n",
    "    # Get the list of shared_items\n",
    "    si={}\n",
    "    for item in prefs[person1]: \n",
    "        if item in prefs[person2]: si[item]=1\n",
    "\n",
    "    # if they have no ratings in common, return 0\n",
    "    if len(si)==0: return 0\n",
    "\n",
    "    # Add up the squares of all the differences\n",
    "    sum_of_squares=sum([pow(prefs[person1][item]-prefs[person2][item],2) \n",
    "                        for item in prefs[person1] if item in prefs[person2]])\n",
    "\n",
    "    return 1/(1+sum_of_squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the Pearson correlation coefficient for p1 and p2\n",
    "def sim_pearson(prefs,p1,p2):\n",
    "    # Get the list of mutually rated items\n",
    "    si={}\n",
    "    for item in prefs[p1]: \n",
    "        if item in prefs[p2]: si[item]=1\n",
    "\n",
    "    # if they are no ratings in common, return 0\n",
    "    if len(si)==0: return 0\n",
    "\n",
    "    # Sum calculations\n",
    "    n=len(si)\n",
    "    \n",
    "    # Sums of all the preferences\n",
    "    sum1=sum([prefs[p1][it] for it in si])\n",
    "    sum2=sum([prefs[p2][it] for it in si])\n",
    "    \n",
    "    # Sums of the squares\n",
    "    sum1Sq=sum([pow(prefs[p1][it],2) for it in si])\n",
    "    sum2Sq=sum([pow(prefs[p2][it],2) for it in si]) \n",
    "    \n",
    "    # Sum of the products\n",
    "    pSum=sum([prefs[p1][it]*prefs[p2][it] for it in si])\n",
    "    \n",
    "    # Calculate r (Pearson score)\n",
    "    num=pSum-(sum1*sum2/n)\n",
    "    den=sqrt((sum1Sq-pow(sum1,2)/n)*(sum2Sq-pow(sum2,2)/n))\n",
    "    if den==0: return 0\n",
    "\n",
    "    r=num/den\n",
    "\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(test_size=0.2, datafile='ml-100k/u.data', header=['uid','iid','ratings','timestamp'], sep='\\t', seed=0):\n",
    "    # Read CSV File into A Pandas DataFrame\n",
    "    df = pd.read_csv(datafile, header=None, names=header, sep=sep, engine='python')\n",
    "    df.drop(columns='timestamp')\n",
    "    print(df.head())\n",
    "    # The Number of User and Items\n",
    "    num_users, num_items = df[header[0]].unique().shape[0], df[header[1]].unique().shape[0]\n",
    "    # The minimum id of user and item (because in Python array index is from 0)\n",
    "    uid_min, iid_min = df['uid'].min(), df['iid'].min()\n",
    "\n",
    "    # Train and Test Dataset Splitting\n",
    "    train_df, test_df = train_test_split(np.asarray(df), test_size=test_size, random_state=seed)\n",
    "\n",
    "    # Change the data structure into sparse matrix\n",
    "    train = sp.csr_matrix((train_df[:, 2], (train_df[:, 0]-uid_min, train_df[:, 1]-iid_min)), shape=(num_users, num_items))\n",
    "    test = sp.csr_matrix((test_df[:, 2], (test_df[:, 0]-uid_min, test_df[:, 1]-iid_min)), shape=(num_users, num_items))\n",
    "\n",
    "    print(\"Number of Users: \" + str(num_users))\n",
    "    print(\"Number of Items: \" + str(num_items))\n",
    "    print(\"=\" * 120)\n",
    "\n",
    "    print(\"Sample Data: \" + str(train.getrow(0).toarray()))\n",
    "    print(\"=\" * 120)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "# def loadData(test_size=0.2, datafile='ml-100k/u.data', header=['uid','iid','ratings','timestamp'], sep='\\t', seed=0):\n",
    "#     # Read CSV File into A Pandas DataFrame\n",
    "#     df = pd.read_csv(datafile, header=None, names=header, sep=sep, engine='python')\n",
    "#     df = df.drop(columns='timestamp')\n",
    "#     print(df.head())\n",
    "#     # The Number of User and Items\n",
    "#     num_users, num_items = df[header[0]].unique().shape[0], df[header[1]].unique().shape[0]\n",
    "#     # The minimum id of user and item (because in Python array index is from 0)\n",
    "#     uid_min, iid_min = df['uid'].min(), df['iid'].min()\n",
    "#     uid_max, iid_max = df['uid'].max(), df['iid'].max()\n",
    "# #     print(uid_max,iid_max)\n",
    "# #     print(num_users)\n",
    "#     result = np.zeros((num_users, num_items))\n",
    "#     for index, row in df.iterrows():\n",
    "#         result[int(row['uid'])-1,int(row['iid'])-1] = int(row['ratings'])\n",
    "#     train, test = train_test_split(result, test_size=test_size, random_state = seed)\n",
    "#     return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Precision_and_Recall(pred_item_list, test_item_list):\n",
    "    # Calculate the Number of Occurrences of Testing Item IDs in the Prediction Item ID List\n",
    "    sum_relevant_item = 0\n",
    "    for item in test_item_list:\n",
    "        if item in pred_item_list:\n",
    "            sum_relevant_item += 1\n",
    "\n",
    "    # Calculate the Precision and Recall Value\n",
    "    precision = sum_relevant_item / len(pred_item_list)\n",
    "    recall = sum_relevant_item / len(test_item_list)\n",
    "\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   uid  iid  ratings  timestamp\n",
      "0  196  242        3  881250949\n",
      "1  186  302        3  891717742\n",
      "2   22  377        1  878887116\n",
      "3  244   51        2  880606923\n",
      "4  166  346        1  886397596\n",
      "Number of Users: 943\n",
      "Number of Items: 1682\n",
      "========================================================================================================================\n",
      "Sample Data: [[5 3 4 ... 0 0 0]]\n",
      "========================================================================================================================\n",
      "<class 'numpy.ndarray'>\n",
      "(943, 1682)\n",
      "(943, 1682)\n"
     ]
    }
   ],
   "source": [
    "train, test = loadData()\n",
    "train = train.toarray()\n",
    "test = test.toarray()\n",
    "print(type(train))\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils import *\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "\n",
    "class SVD(object):\n",
    "    def __init__(self,train_matrix,test_matrix):\n",
    "        # Initialize Parameters\n",
    "        self.num_factors = 600 # Dimension of the Latent Factor\n",
    "        self.regs = 1e-3 # Regularizer Coefficient\n",
    "        self.lr = 0.01 # Learning Rate\n",
    "        self.trains = 50 # How many number of Training Loops\n",
    "        self.batch_size = 228 # How many data is fed into the training algorithm in each training\n",
    "        self.num_user, self.num_item = train_matrix.shape[0], train_matrix.shape[1]\n",
    "\n",
    "        # Store the user IDs in a list, the item IDs in a list and the ratings in a list\n",
    "        train_matrix, test_matrix = train_matrix.tocoo(), test_matrix.tocoo()\n",
    "        self.train_uid, self.train_iid, self.train_ratings = list(train_matrix.row),list(train_matrix.col),list(train_matrix.data)\n",
    "        self.test_uid, self.test_iid, self.test_ratings = list(test_matrix.row),list(test_matrix.col),list(test_matrix.data)\n",
    "\n",
    "        # Calculate the average of all ratings (the mu value in the equation)\n",
    "        self.mu = np.mean(self.train_ratings)\n",
    "\n",
    "        # Total number of training data instances\n",
    "        self.num_training = len(self.train_ratings)\n",
    "\n",
    "        # Number of batches\n",
    "        self.num_batch = int(self.num_training / self.batch_size)\n",
    "        print(\"Data Preparation Completed.\")\n",
    "\n",
    "    # Build the model for customized SGD algorithm\n",
    "        # Initialize all the parameters (Use Normal Distribution)\n",
    "        # bu and bi are vectors (Note the dimension)\n",
    "        self.bu = np.random.normal(scale = 1. / self.num_factors, size=[self.num_user])\n",
    "        self.bi = np.random.normal(scale = 1. / self.num_factors, size=[self.num_item])\n",
    "\n",
    "        # P and Q are matrices (Note the dimension)\n",
    "        self.P = np.random.normal(scale=1. / self.num_factors, size=[self.num_user, self.num_factors])\n",
    "        self.Q = np.random.normal(scale=1. / self.num_factors, size=[self.num_factors, self.num_item])\n",
    "        print(\"Parameter Initialization Completed.\")\n",
    "\n",
    "    # Training using SGD algorithm\n",
    "    def train_and_evaluate(self):\n",
    "        self.train_result = []\n",
    "        self.test_result = []\n",
    "        for tr in range(self.trains):\n",
    "            for uid, iid, ratings in list(zip(self.train_uid, self.train_iid, self.train_ratings)):\n",
    "                # The estimated rating\n",
    "                pred_r = self.mu + self.bu[uid] + self.bi[iid] + np.dot(self.Q[:, iid], self.P[uid, :])\n",
    "\n",
    "                # Calculate the loss of this specific user-item pair\n",
    "                error = ratings - pred_r\n",
    "\n",
    "                # Update the parameters\n",
    "                self.bu[uid] = self.bu[uid] + self.lr * (error - self.regs * self.bu[uid])\n",
    "                self.bi[iid] = self.bi[iid] + self.lr * (error - self.regs * self.bi[iid])\n",
    "                self.P[uid, :] = self.P[uid, :] + self.lr * (error * self.Q[:, iid] - self.regs * self.P[uid, :])\n",
    "                self.Q[:, iid] = self.Q[:, iid] + self.lr * (error * self.P[uid, :] - self.regs * self.Q[:, iid])\n",
    "            rms_test_list, rms_train_list = [], []\n",
    "            \n",
    "            for test in range(len(self.test_uid)):\n",
    "                uid = self.test_uid[test]\n",
    "                iid = self.test_iid[test]\n",
    "                ratings = self.test_ratings[test]\n",
    "                rms_test_list.append((self.mu + self.bu[uid] + self.bi[iid] + np.dot(self.Q[:, iid], self.P[uid, :]) - ratings) ** 2)\n",
    "                \n",
    "            for train in range(len(self.train_uid)):\n",
    "                uid = self.train_uid[train]\n",
    "                iid = self.train_iid[train]\n",
    "                ratings = self.train_ratings[train]\n",
    "                rms_train_list.append((self.mu + self.bu[uid] + self.bi[iid] + np.dot(self.Q[:, iid], self.P[uid, :]) - ratings) ** 2)\n",
    "    \n",
    "            rms_test = np.sqrt(np.mean(rms_test_list))\n",
    "            self.test_result.append(rms_test)\n",
    "            rms_train = np.sqrt(np.mean(rms_train_list))\n",
    "            self.train_result.append(rms_train)\n",
    "            print(\"The {0} Training: [RMS] {1} and Testing: [RMS] {2}\".format(tr, rms_train, rms_test))\n",
    "    def plot(self):\n",
    "        x_axis = range(1,self.trains+1)\n",
    "        plt.plot(x_axis, self.test_result, color='red', label='test result')\n",
    "        plt.plot(x_axis, self.train_result, color='green', label='train result')\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   uid  iid  ratings  timestamp\n",
      "0  196  242        3  881250949\n",
      "1  186  302        3  891717742\n",
      "2   22  377        1  878887116\n",
      "3  244   51        2  880606923\n",
      "4  166  346        1  886397596\n",
      "Number of Users: 943\n",
      "Number of Items: 1682\n",
      "========================================================================================================================\n",
      "Sample Data: [[5 3 4 ... 0 0 0]]\n",
      "========================================================================================================================\n",
      "Data Preparation Completed.\n",
      "Parameter Initialization Completed.\n",
      "The 0 Training: [RMS] 0.9709923582837396 and Testing: [RMS] 0.9846878922687593\n",
      "The 1 Training: [RMS] 0.9470189774935223 and Testing: [RMS] 0.9648254498449591\n",
      "The 2 Training: [RMS] 0.9362251519181061 and Testing: [RMS] 0.9564674638430254\n",
      "The 3 Training: [RMS] 0.9300637182429145 and Testing: [RMS] 0.9520390200078159\n",
      "The 4 Training: [RMS] 0.9261373939368877 and Testing: [RMS] 0.9494470389674456\n",
      "The 5 Training: [RMS] 0.9234246024462673 and Testing: [RMS] 0.9478246613838495\n",
      "The 6 Training: [RMS] 0.9213923266181112 and Testing: [RMS] 0.9467425123610689\n",
      "The 7 Training: [RMS] 0.9197057265576842 and Testing: [RMS] 0.9459555302579361\n",
      "The 8 Training: [RMS] 0.9180932026839039 and Testing: [RMS] 0.9452928898372249\n",
      "The 9 Training: [RMS] 0.9162531425811369 and Testing: [RMS] 0.9445923684989063\n",
      "The 10 Training: [RMS] 0.9137595733874 and Testing: [RMS] 0.9436446841954524\n",
      "The 11 Training: [RMS] 0.9099638908414469 and Testing: [RMS] 0.942145519431046\n",
      "The 12 Training: [RMS] 0.9039765190990757 and Testing: [RMS] 0.9397110515894238\n",
      "The 13 Training: [RMS] 0.8949561358779164 and Testing: [RMS] 0.9360959871856119\n",
      "The 14 Training: [RMS] 0.8827700185703078 and Testing: [RMS] 0.9316024740553162\n",
      "The 15 Training: [RMS] 0.8681642216776654 and Testing: [RMS] 0.927046562441991\n",
      "The 16 Training: [RMS] 0.8517946970594296 and Testing: [RMS] 0.922989930021991\n",
      "The 17 Training: [RMS] 0.8336559809309508 and Testing: [RMS] 0.9194682554113189\n",
      "The 18 Training: [RMS] 0.8134979142247368 and Testing: [RMS] 0.9164215191571802\n",
      "The 19 Training: [RMS] 0.7911458727941282 and Testing: [RMS] 0.913898364566508\n",
      "The 20 Training: [RMS] 0.7665928263459982 and Testing: [RMS] 0.9120051983104475\n",
      "The 21 Training: [RMS] 0.7400101911714944 and Testing: [RMS] 0.9108212374006094\n",
      "The 22 Training: [RMS] 0.7116818476966223 and Testing: [RMS] 0.9103588250244298\n",
      "The 23 Training: [RMS] 0.6819637375921679 and Testing: [RMS] 0.910584011431219\n",
      "The 24 Training: [RMS] 0.6512792162304943 and Testing: [RMS] 0.9114475672283273\n",
      "The 25 Training: [RMS] 0.6200936370687508 and Testing: [RMS] 0.9128921825024626\n",
      "The 26 Training: [RMS] 0.5888681615320492 and Testing: [RMS] 0.9148462529439152\n",
      "The 27 Training: [RMS] 0.5580176539987898 and Testing: [RMS] 0.9172207841497101\n",
      "The 28 Training: [RMS] 0.5278840046871797 and Testing: [RMS] 0.9199138498815055\n",
      "The 29 Training: [RMS] 0.49872625635768797 and Testing: [RMS] 0.9228201777162869\n",
      "The 30 Training: [RMS] 0.4707245931779645 and Testing: [RMS] 0.9258416287170421\n",
      "The 31 Training: [RMS] 0.4439923184027393 and Testing: [RMS] 0.9288948757971166\n",
      "The 32 Training: [RMS] 0.4185900115933443 and Testing: [RMS] 0.931914719022895\n",
      "The 33 Training: [RMS] 0.3945385428480546 and Testing: [RMS] 0.9348536721612257\n",
      "The 34 Training: [RMS] 0.37182991333073906 and Testing: [RMS] 0.9376794349878557\n",
      "The 35 Training: [RMS] 0.35043589856172214 and Testing: [RMS] 0.9403716965698102\n",
      "The 36 Training: [RMS] 0.3303146938420721 and Testing: [RMS] 0.942919117212051\n",
      "The 37 Training: [RMS] 0.3114158165483072 and Testing: [RMS] 0.9453168263300504\n",
      "The 38 Training: [RMS] 0.2936835861007965 and Testing: [RMS] 0.9475644858321339\n",
      "The 39 Training: [RMS] 0.2770595348500918 and Testing: [RMS] 0.9496648490249904\n",
      "The 40 Training: [RMS] 0.2614840703752258 and Testing: [RMS] 0.9516227134011087\n",
      "The 41 Training: [RMS] 0.24689763536553622 and Testing: [RMS] 0.9534441707719571\n",
      "The 42 Training: [RMS] 0.23324153264792832 and Testing: [RMS] 0.9551360754364202\n",
      "The 43 Training: [RMS] 0.22045852153539644 and Testing: [RMS] 0.9567056698416158\n",
      "The 44 Training: [RMS] 0.20849325132536783 and Testing: [RMS] 0.9581603233433534\n",
      "The 45 Training: [RMS] 0.19729257360954697 and Testing: [RMS] 0.9595073520936784\n",
      "The 46 Training: [RMS] 0.18680576094283163 and Testing: [RMS] 0.9607538970917646\n",
      "The 47 Training: [RMS] 0.17698465095129837 and Testing: [RMS] 0.961906843837265\n",
      "The 48 Training: [RMS] 0.16778372966126964 and Testing: [RMS] 0.9629727716031612\n",
      "The 49 Training: [RMS] 0.15916016446259143 and Testing: [RMS] 0.9639579236718687\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    train_matrix, test_matrix = loadData()\n",
    "    model = SVD(train_matrix, test_matrix)\n",
    "    model.train_and_evaluate()\n",
    "    model.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

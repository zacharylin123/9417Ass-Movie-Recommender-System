{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.sparse as sp\n",
    "\n",
    "data_100k = 'ml-100k/u.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosSimilarity(matrix):\n",
    "    similarity_matrix = cosine_similarity(matrix)\n",
    "    print(\"Cosine Similarity Matrix Sample:\")\n",
    "    print(similarity_matrix[:5, :5])\n",
    "    print(\"=\" * 120)\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns a distance-based similarity score for person1 and person2\n",
    "def sim_distance(prefs,person1,person2):\n",
    "    # Get the list of shared_items\n",
    "    si={}\n",
    "    for item in prefs[person1]: \n",
    "        if item in prefs[person2]: si[item]=1\n",
    "\n",
    "    # if they have no ratings in common, return 0\n",
    "    if len(si)==0: return 0\n",
    "\n",
    "    # Add up the squares of all the differences\n",
    "    sum_of_squares=sum([pow(prefs[person1][item]-prefs[person2][item],2) \n",
    "                        for item in prefs[person1] if item in prefs[person2]])\n",
    "\n",
    "    return 1/(1+sum_of_squares)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns the Pearson correlation coefficient for p1 and p2\n",
    "def sim_pearson(prefs,p1,p2):\n",
    "    # Get the list of mutually rated items\n",
    "    si={}\n",
    "    for item in prefs[p1]: \n",
    "        if item in prefs[p2]: si[item]=1\n",
    "\n",
    "    # if they are no ratings in common, return 0\n",
    "    if len(si)==0: return 0\n",
    "\n",
    "    # Sum calculations\n",
    "    n=len(si)\n",
    "    \n",
    "    # Sums of all the preferences\n",
    "    sum1=sum([prefs[p1][it] for it in si])\n",
    "    sum2=sum([prefs[p2][it] for it in si])\n",
    "    \n",
    "    # Sums of the squares\n",
    "    sum1Sq=sum([pow(prefs[p1][it],2) for it in si])\n",
    "    sum2Sq=sum([pow(prefs[p2][it],2) for it in si]) \n",
    "    \n",
    "    # Sum of the products\n",
    "    pSum=sum([prefs[p1][it]*prefs[p2][it] for it in si])\n",
    "    \n",
    "    # Calculate r (Pearson score)\n",
    "    num=pSum-(sum1*sum2/n)\n",
    "    den=sqrt((sum1Sq-pow(sum1,2)/n)*(sum2Sq-pow(sum2,2)/n))\n",
    "    if den==0: return 0\n",
    "\n",
    "    r=num/den\n",
    "\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(test_size=0.2, datafile='ml-100k/u.data', header=['uid','iid','ratings','timestamp'], sep='\\t', seed=0):\n",
    "    # Read CSV File into A Pandas DataFrame\n",
    "    df = pd.read_csv(datafile, header=None, names=header, sep=sep, engine='python')\n",
    "    df.drop(columns='timestamp')\n",
    "    print(df.head())\n",
    "    # The Number of User and Items\n",
    "    num_users, num_items = df[header[0]].unique().shape[0], df[header[1]].unique().shape[0]\n",
    "    # The minimum id of user and item (because in Python array index is from 0)\n",
    "    uid_min, iid_min = df['uid'].min(), df['iid'].min()\n",
    "\n",
    "    # Train and Test Dataset Splitting\n",
    "    train_df, test_df = train_test_split(np.asarray(df), test_size=test_size, random_state=seed)\n",
    "\n",
    "    # Change the data structure into sparse matrix\n",
    "    train = sp.csr_matrix((train_df[:, 2], (train_df[:, 0]-uid_min, train_df[:, 1]-iid_min)), shape=(num_users, num_items))\n",
    "    test = sp.csr_matrix((test_df[:, 2], (test_df[:, 0]-uid_min, test_df[:, 1]-iid_min)), shape=(num_users, num_items))\n",
    "\n",
    "    print(\"Number of Users: \" + str(num_users))\n",
    "    print(\"Number of Items: \" + str(num_items))\n",
    "    print(\"=\" * 120)\n",
    "\n",
    "    print(\"Sample Data: \" + str(train.getrow(0).toarray()))\n",
    "    print(\"=\" * 120)\n",
    "\n",
    "    return train, test\n",
    "\n",
    "\n",
    "# def loadData(test_size=0.2, datafile='ml-100k/u.data', header=['uid','iid','ratings','timestamp'], sep='\\t', seed=0):\n",
    "#     # Read CSV File into A Pandas DataFrame\n",
    "#     df = pd.read_csv(datafile, header=None, names=header, sep=sep, engine='python')\n",
    "#     df = df.drop(columns='timestamp')\n",
    "#     print(df.head())\n",
    "#     # The Number of User and Items\n",
    "#     num_users, num_items = df[header[0]].unique().shape[0], df[header[1]].unique().shape[0]\n",
    "#     # The minimum id of user and item (because in Python array index is from 0)\n",
    "#     uid_min, iid_min = df['uid'].min(), df['iid'].min()\n",
    "#     uid_max, iid_max = df['uid'].max(), df['iid'].max()\n",
    "# #     print(uid_max,iid_max)\n",
    "# #     print(num_users)\n",
    "#     result = np.zeros((num_users, num_items))\n",
    "#     for index, row in df.iterrows():\n",
    "#         result[int(row['uid'])-1,int(row['iid'])-1] = int(row['ratings'])\n",
    "#     train, test = train_test_split(result, test_size=test_size, random_state = seed)\n",
    "#     return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Precision_and_Recall(pred_item_list, test_item_list):\n",
    "    # Calculate the Number of Occurrences of Testing Item IDs in the Prediction Item ID List\n",
    "    sum_relevant_item = 0\n",
    "    for item in test_item_list:\n",
    "        if item in pred_item_list:\n",
    "            sum_relevant_item += 1\n",
    "\n",
    "    # Calculate the Precision and Recall Value\n",
    "    precision = sum_relevant_item / len(pred_item_list)\n",
    "    recall = sum_relevant_item / len(test_item_list)\n",
    "\n",
    "    return precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   uid  iid  ratings  timestamp\n",
      "0  196  242        3  881250949\n",
      "1  186  302        3  891717742\n",
      "2   22  377        1  878887116\n",
      "3  244   51        2  880606923\n",
      "4  166  346        1  886397596\n",
      "Number of Users: 943\n",
      "Number of Items: 1682\n",
      "========================================================================================================================\n",
      "Sample Data: [[5 3 4 ... 0 0 0]]\n",
      "========================================================================================================================\n",
      "<class 'numpy.ndarray'>\n",
      "(943, 1682)\n",
      "(943, 1682)\n"
     ]
    }
   ],
   "source": [
    "train, test = loadData()\n",
    "train = train.toarray()\n",
    "test = test.toarray()\n",
    "print(type(train))\n",
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVD:\n",
    "    def __init__(self,mat,K=20):\n",
    "        self.mat=mat\n",
    "        self.K=K\n",
    "        self.bi={}\n",
    "        self.bu={}\n",
    "        self.qi={}\n",
    "        self.pu={}\n",
    "        self.avg=np.mean(self.mat[:,2])\n",
    "        for i in range(self.mat.shape[0]):\n",
    "            uid=self.mat[i,0]\n",
    "            iid=self.mat[i,1]\n",
    "            self.bi.setdefault(iid,0)\n",
    "            self.bu.setdefault(uid,0)\n",
    "            self.qi.setdefault(iid,np.random.random((self.K,1))/10*np.sqrt(self.K))\n",
    "            self.pu.setdefault(uid,np.random.random((self.K,1))/10*np.sqrt(self.K))\n",
    "    def predict(self,uid,iid):  #预测评分的函数\n",
    "        #setdefault的作用是当该用户或者物品未出现过时，新建它的bi,bu,qi,pu，并设置初始值为0\n",
    "        self.bi.setdefault(iid,0)\n",
    "        self.bu.setdefault(uid,0)\n",
    "        self.qi.setdefault(iid,np.zeros((self.K,1)))\n",
    "        self.pu.setdefault(uid,np.zeros((self.K,1)))\n",
    "        rating=self.avg+self.bi[iid]+self.bu[uid]+np.sum(self.qi[iid]*self.pu[uid]) #预测评分公式\n",
    "        #由于评分范围在1到5，所以当分数大于5或小于1时，返回5,1.\n",
    "        if rating>5:\n",
    "            rating=5\n",
    "        if rating<1:\n",
    "            rating=1\n",
    "        return rating\n",
    "    def train(self,steps=30,gamma=0.04,Lambda=0.15):    #训练函数，step为迭代次数\n",
    "        print('train data size',self.mat.shape)\n",
    "        for step in range(steps):\n",
    "            print('step',step+1,'is running')\n",
    "            KK=np.random.permutation(self.mat.shape[0]) #随机梯度下降算法，kk为对矩阵进行随机洗牌\n",
    "            rmse=0.0\n",
    "            for i in range(self.mat.shape[0]):\n",
    "                j=KK[i]\n",
    "                uid=self.mat[j,0]\n",
    "                iid=self.mat[j,1]\n",
    "                rating=self.mat[j,2]\n",
    "                eui=rating-self.predict(uid, iid)\n",
    "                rmse+=eui**2\n",
    "                self.bu[uid]+=gamma*(eui-Lambda*self.bu[uid])  \n",
    "                self.bi[iid]+=gamma*(eui-Lambda*self.bi[iid])\n",
    "                tmp=self.qi[iid]\n",
    "                self.qi[iid]+=gamma*(eui*self.pu[uid]-Lambda*self.qi[iid])\n",
    "                self.pu[uid]+=gamma*(eui*tmp-Lambda*self.pu[uid])\n",
    "            gamma=0.93*gamma\n",
    "            print('rmse is',np.sqrt(rmse/self.mat.shape[0]))\n",
    "    def test(self,test_data):  #gamma以0.93的学习率递减\n",
    "        test_data=test_data\n",
    "        print('test data size',test_data.shape)\n",
    "        rmse=0.0\n",
    "        for i in range(test_data.shape[0]):\n",
    "            uid=test_data[i,0]\n",
    "            iid=test_data[i,1]\n",
    "            rating=test_data[i,2]\n",
    "            eui=rating-self.predict(uid, iid)\n",
    "            rmse+=eui**2\n",
    "        print('rmse of test data is',np.sqrt(rmse/test_data.shape[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size (943, 1682)\n",
      "step 1 is running\n",
      "rmse is 1.2896900428768914\n",
      "step 2 is running\n",
      "rmse is 1.3263781124312921\n",
      "step 3 is running\n",
      "rmse is 1.3231762293966352\n",
      "step 4 is running\n",
      "rmse is 1.277507514924781\n",
      "step 5 is running\n",
      "rmse is 1.2641563187767908\n",
      "step 6 is running\n",
      "rmse is 1.2841310590754709\n",
      "step 7 is running\n",
      "rmse is 1.2675073023062975\n",
      "step 8 is running\n",
      "rmse is 1.2370217029346264\n",
      "step 9 is running\n",
      "rmse is 1.2741828313051424\n",
      "step 10 is running\n",
      "rmse is 1.2162735362377495\n",
      "step 11 is running\n",
      "rmse is 1.2022425140404402\n",
      "step 12 is running\n",
      "rmse is 1.2197560731756085\n",
      "step 13 is running\n",
      "rmse is 1.1844700279381388\n",
      "step 14 is running\n",
      "rmse is 1.2266914869851269\n",
      "step 15 is running\n",
      "rmse is 1.2162735362377495\n",
      "step 16 is running\n",
      "rmse is 1.2057655765789546\n",
      "step 17 is running\n",
      "rmse is 1.2266914869851269\n",
      "step 18 is running\n",
      "rmse is 1.2057655765789546\n",
      "step 19 is running\n",
      "rmse is 1.2057655765789546\n",
      "step 20 is running\n",
      "rmse is 1.1844700279381388\n",
      "step 21 is running\n",
      "rmse is 1.2057655765789546\n",
      "step 22 is running\n",
      "rmse is 1.1772859129755924\n",
      "step 23 is running\n",
      "rmse is 1.1664267793570553\n",
      "step 24 is running\n",
      "rmse is 1.2092783752136143\n",
      "step 25 is running\n",
      "rmse is 1.1736773652900843\n",
      "step 26 is running\n",
      "rmse is 1.1880457946477803\n",
      "step 27 is running\n",
      "rmse is 1.1736773652900843\n",
      "step 28 is running\n",
      "rmse is 1.1664267793570553\n",
      "step 29 is running\n",
      "rmse is 1.1844700279381388\n",
      "step 30 is running\n",
      "rmse is 1.1844700279381388\n",
      "test data size (943, 1682)\n",
      "rmse of test data is 1.042063374441338\n"
     ]
    }
   ],
   "source": [
    "a=SVD(train,30)  \n",
    "a.train()\n",
    "a.test(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
